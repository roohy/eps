{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from pseudo_sampler.eps import EPS\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('/Users/Roohy/Downloads/Dataset/np_format.npy')\n",
    "labels = dataset[:,-1]\n",
    "data = dataset[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = EPS(data,labels,[250,120,60,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING VARIATIONAL:\n",
      "TRAINIG LATENT SPACE REGRESSOR:\n",
      "[Epoch 0] Loss: 0.6931468844413757\n",
      "[Epoch 5] Loss: 0.6889384984970093\n",
      "[Epoch 5] Loss: 0.6870465874671936\n",
      "[Epoch 10] Loss: 0.679470956325531\n",
      "[Epoch 10] Loss: 0.6818027496337891\n",
      "[Epoch 15] Loss: 0.6757567524909973\n",
      "[Epoch 15] Loss: 0.6758180856704712\n",
      "[Epoch 20] Loss: 0.6694501042366028\n",
      "[Epoch 20] Loss: 0.6698698997497559\n",
      "[Epoch 25] Loss: 0.661834716796875\n",
      "[Epoch 25] Loss: 0.665927529335022\n",
      "[Epoch 30] Loss: 0.661932110786438\n",
      "[Epoch 30] Loss: 0.6610055565834045\n",
      "[Epoch 35] Loss: 0.6544933319091797\n",
      "[Epoch 35] Loss: 0.6567186117172241\n",
      "[Epoch 40] Loss: 0.6559776663780212\n",
      "[Epoch 40] Loss: 0.6480711102485657\n",
      "[Epoch 45] Loss: 0.643907904624939\n",
      "[Epoch 45] Loss: 0.6456901431083679\n",
      "[Epoch 50] Loss: 0.6317048668861389\n",
      "[Epoch 50] Loss: 0.6389492154121399\n",
      "[Epoch 55] Loss: 0.6425549983978271\n",
      "[Epoch 55] Loss: 0.6362304091453552\n",
      "[Epoch 60] Loss: 0.6237479448318481\n",
      "[Epoch 60] Loss: 0.6339170336723328\n",
      "[Epoch 65] Loss: 0.6095646619796753\n",
      "[Epoch 65] Loss: 0.6279017925262451\n",
      "[Epoch 70] Loss: 0.6342325806617737\n",
      "[Epoch 70] Loss: 0.622546911239624\n",
      "[Epoch 75] Loss: 0.6248714327812195\n",
      "[Epoch 75] Loss: 0.6192216277122498\n",
      "[Epoch 80] Loss: 0.6237542033195496\n",
      "[Epoch 80] Loss: 0.6164129376411438\n",
      "[Epoch 85] Loss: 0.623151957988739\n",
      "[Epoch 85] Loss: 0.61015385389328\n",
      "[Epoch 90] Loss: 0.5846120715141296\n",
      "[Epoch 90] Loss: 0.6047888994216919\n",
      "[Epoch 95] Loss: 0.6058146953582764\n",
      "[Epoch 95] Loss: 0.6074407696723938\n",
      "[Epoch 100] Loss: 0.6034262776374817\n",
      "Latent Regressor Accuracy is : 0.782841823056\n",
      "INFO:tensorflow:Restoring parameters from ./vae_mode.ckpt\n",
      "INITIATING EXAGGERATED REGRESSOR...\n",
      "TRAINIG LATENT SPACE REGRESSOR:\n",
      "[Epoch 0] Loss: 0.6931468844413757\n",
      "[Epoch 5] Loss: 0.6549075245857239\n",
      "[Epoch 5] Loss: 0.6507799029350281\n",
      "[Epoch 10] Loss: 0.6141147017478943\n",
      "[Epoch 10] Loss: 0.6106799840927124\n",
      "[Epoch 15] Loss: 0.5769274830818176\n",
      "[Epoch 15] Loss: 0.5731542706489563\n",
      "[Epoch 20] Loss: 0.5432186722755432\n",
      "[Epoch 20] Loss: 0.5377112030982971\n",
      "[Epoch 25] Loss: 0.5092809200286865\n",
      "[Epoch 25] Loss: 0.505754292011261\n",
      "[Epoch 30] Loss: 0.4798147678375244\n",
      "[Epoch 30] Loss: 0.4743616282939911\n",
      "[Epoch 35] Loss: 0.4477554261684418\n",
      "[Epoch 35] Loss: 0.4462432861328125\n",
      "[Epoch 40] Loss: 0.4251449704170227\n",
      "[Epoch 40] Loss: 0.41973695158958435\n",
      "[Epoch 45] Loss: 0.39606231451034546\n",
      "[Epoch 45] Loss: 0.39684128761291504\n",
      "[Epoch 50] Loss: 0.37680914998054504\n",
      "[Epoch 50] Loss: 0.37416592240333557\n",
      "[Epoch 55] Loss: 0.3565715551376343\n",
      "[Epoch 55] Loss: 0.35241633653640747\n",
      "[Epoch 60] Loss: 0.33346056938171387\n",
      "[Epoch 60] Loss: 0.3327562212944031\n",
      "[Epoch 65] Loss: 0.3141118288040161\n",
      "[Epoch 65] Loss: 0.3144681453704834\n",
      "[Epoch 70] Loss: 0.3018660843372345\n",
      "[Epoch 70] Loss: 0.29822129011154175\n",
      "[Epoch 75] Loss: 0.27983132004737854\n",
      "[Epoch 75] Loss: 0.28278473019599915\n",
      "[Epoch 80] Loss: 0.27042388916015625\n",
      "[Epoch 80] Loss: 0.2685268521308899\n",
      "[Epoch 85] Loss: 0.2548898160457611\n",
      "[Epoch 85] Loss: 0.25393742322921753\n",
      "[Epoch 90] Loss: 0.24662025272846222\n",
      "[Epoch 90] Loss: 0.24281062185764313\n",
      "[Epoch 95] Loss: 0.2316562533378601\n",
      "[Epoch 95] Loss: 0.2309260368347168\n",
      "[Epoch 100] Loss: 0.22067758440971375\n",
      "Latent Regressor Accuracy is : 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([362, 348,  52, 424,  50, 400, 234, 196,  73, 504, 343, 310, 297,\n",
       "        47, 422, 189, 417,  31, 291, 256, 383, 367,  55, 237, 502, 331,\n",
       "        83, 278, 243, 131, 357, 133, 100, 150, 473, 257, 410, 432, 349,\n",
       "        74, 434, 497, 524,  43, 324, 368, 475,  41, 447, 186, 255, 401,\n",
       "       316,   4,  23, 518, 134, 111, 404, 306, 420, 332, 203, 458,  60,\n",
       "       527, 209, 445,  19, 289, 396, 161, 127, 304, 374, 511, 269, 298,\n",
       "       302, 469, 358, 235, 329, 377,  22, 124,  93, 507, 262, 350, 470,\n",
       "       352, 354, 512, 430,  94, 114,  66, 152,  70, 402,  35, 261, 187,\n",
       "       294, 496, 277,  10, 477,  56, 474, 158, 308,  69, 407, 155,  87,\n",
       "        40, 498, 140, 240, 146, 172, 327, 388, 326, 148, 500, 113, 318,\n",
       "       176, 501, 317, 228, 312, 443, 153, 480, 328, 198, 126, 381, 171,\n",
       "       174, 251,  81, 138,  75, 414, 525, 259, 454, 517, 382, 149, 181,\n",
       "       465, 452, 241, 169, 177,  21, 271, 128, 528, 191,  45, 483, 488,\n",
       "        71, 129, 463, 342, 110, 333, 163,  48, 305, 281,  13, 202, 288,\n",
       "       112, 448, 408, 160, 142, 361, 514, 248, 459, 249, 471, 159, 115,\n",
       "       173, 245, 178,  24, 461, 390, 122, 436,  68,  16, 130, 384, 156,\n",
       "       405, 184, 218, 284, 267, 426, 283, 337, 101, 120,  38, 359, 444,\n",
       "       371, 423, 226, 307, 322, 468,  34, 260, 478, 220, 411,  90, 395,\n",
       "         2, 208, 314, 406, 212, 486, 119, 254,  29, 522, 325, 520, 472,\n",
       "       300, 108, 418, 215,  25, 487, 375, 313, 453, 264,  80, 239, 236,\n",
       "        12,  54,  95, 195, 224, 263, 510, 494,  78,  58, 136, 309, 529,\n",
       "       230, 508,  91, 364, 464, 346, 183, 214, 386,  36, 479, 391, 392,\n",
       "       247, 253, 416, 242, 394, 293, 143, 104, 482, 276, 273, 356, 311,\n",
       "       516, 185, 355, 429,  77,  86, 286, 180, 428,  17, 190, 279, 232,\n",
       "       223, 201, 365,  64, 336,  62, 217, 204, 292, 484, 441, 109, 165,\n",
       "       513, 211, 192, 272,  72, 199, 376, 340, 319, 145, 270, 397, 437,\n",
       "       493, 103, 265, 303, 509, 389, 379, 363, 225, 194, 188, 137,   0,\n",
       "       387, 233, 353, 216, 433, 144, 398, 295, 495,  27, 147, 521,  46,\n",
       "       450, 301, 299,  28, 117, 210, 285, 421, 321, 166, 287, 462, 246,\n",
       "        76, 229, 175, 118, 105, 485,  65, 244, 438, 252,  99, 222,  32,\n",
       "       467, 347, 372, 106, 221, 206,  88, 335, 338, 519,  97, 490, 315,\n",
       "       440, 413,  18, 151, 523, 442, 121, 345,  14, 456, 393,   8, 351,\n",
       "        85, 515, 439,  96, 460,  63, 505, 167,   6, 197, 492, 506, 419,\n",
       "        26, 499, 179, 182,  51, 435, 466, 320, 399,  30, 380, 139, 227,\n",
       "       334, 200, 330,  20,  67, 323, 205,  57, 290, 296, 385, 116,  49,\n",
       "        42, 123, 170, 457, 157,  53, 503,  84, 266, 162, 213,   1,  39,\n",
       "        44, 132, 431, 250, 366, 280,   3, 476, 403,  37, 207, 339, 282,\n",
       "       268, 154, 107, 378,  89,  82, 238,  59, 219, 258, 449, 491, 231,\n",
       "       489, 427, 102,  79, 446, 409,  98, 481,   5, 193, 164, 455,  11,\n",
       "        92, 168, 412, 530, 135, 526,   7, 370,   9, 344,  15, 341, 275,\n",
       "       141, 425, 451,  61, 125,  33, 373, 415, 360, 274, 369])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps.run(regression_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
